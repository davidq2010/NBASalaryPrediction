{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Type, Union, List\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline as skPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pipeline\n",
    "1. Read formatted data as DF\n",
    "2. Add salary tiers to DF\n",
    "3. Retain desired subset of features and remove rest from DF\n",
    "4. Split data into train/test\n",
    "5. Determine transformations for data (numerical/categorical)\n",
    "6. Map numerical/categorical transformations to appropriate features using ColumnTransformer\n",
    "7. Add transformations to a sklearn Pipeline\n",
    "8. Add a predictive model to the same Pipeline\n",
    "9. Fit model on training data\n",
    "10. Cross-validate\n",
    "11. Score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "src_dir = os.getcwd()\n",
    "data_dir = os.path.join(src_dir, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_file = os.path.join(data_dir, \"nba_stats_sal_merged_1990_2017.csv\")\n",
    "merged_data = pd.read_csv(merged_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:\n",
      "       Season End             Player Pos  Age   Tm  BLK  TOV   PF   PTS  \\\n",
      "0            1990         Mark Acres   C   27  ORL   25   70  248   362   \n",
      "1            1990      Michael Adams  PG   27  DEN    3  141  133  1221   \n",
      "2            1990       Mark Aguirre  SF   30  DET   19  121  201  1099   \n",
      "3            1990        Danny Ainge  PG   30  SAC   18  185  238  1342   \n",
      "4            1990        Mark Alarie  PF   26  WSB   39  101  219   860   \n",
      "10639        2017        Cody Zeller  PF   24  CHO   58   65  189   639   \n",
      "10640        2017       Tyler Zeller   C   27  BOS   21   20   61   178   \n",
      "10641        2017  Stephen Zimmerman   C   20  ORL    5    3   17    23   \n",
      "10642        2017        Paul Zipser  SF   22  CHI   16   40   78   240   \n",
      "10643        2017        Ivica Zubac   C   19  LAL   33   30   66   284   \n",
      "\n",
      "         Salary  \n",
      "0        437000  \n",
      "1        825000  \n",
      "2       1115000  \n",
      "3        725000  \n",
      "4        500000  \n",
      "10639  12584270  \n",
      "10640   1709538  \n",
      "10641   1312611  \n",
      "10642   1312611  \n",
      "10643   1312611  \n"
     ]
    }
   ],
   "source": [
    "if debug: \n",
    "    print(\"Input Data:\")\n",
    "    print(merged_data.iloc[list(range(5)) + list(range(-5, 0)), \n",
    "                   list(range(5)) + list(range(-5, 0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps\n",
    "- Already took care of null data (when reading from original CSVs and merging)\n",
    "- Try different normalization, standardization techniques and see effect on performance\n",
    "- The only categorical variable to be encoded is Position; not using Team unfortunately b/c a) teams have changed and b) some players played for multiple teams, and thus have TOT as their team. Note that this variable is not ordinal, it's nominal. Also, beware multicollinearity.\n",
    "- Split data by year, do scaling on separate DataFrames, then concatenate.\n",
    "- Write different scaled data to different CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Salary Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tiers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salary_tiers(num_tiers: int, merged_data: pd.DataFrame):\n",
    "    # Compute max salaries per year\n",
    "    salary_maxes = merged_data.groupby('Season End')['Salary'].max().to_dict()\n",
    "    # Append salary tiers per player in a new column\n",
    "    player_tiers = []\n",
    "    for index, row in merged_data[['Season End', 'Salary']].iterrows():\n",
    "        # +1 so we have num_tiers tiers (so the max falls in the highest tier)\n",
    "        player_tiers.append(int(row['Salary'] / (salary_maxes[row['Season End']]+1) * num_tiers))\n",
    "    if not 'Salary Tier' in merged_data.columns: \n",
    "        merged_data.insert(len(merged_data.columns), 'Salary Tier', pd.Series(player_tiers))\n",
    "    else:\n",
    "        merged_data['Salary Tier'] = pd.Series(player_tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged With Salary Tier:\n",
      "       Season End             Player Pos  Age   Tm  TOV   PF   PTS    Salary  \\\n",
      "0            1990         Mark Acres   C   27  ORL   70  248   362    437000   \n",
      "1            1990      Michael Adams  PG   27  DEN  141  133  1221    825000   \n",
      "2            1990       Mark Aguirre  SF   30  DET  121  201  1099   1115000   \n",
      "3            1990        Danny Ainge  PG   30  SAC  185  238  1342    725000   \n",
      "4            1990        Mark Alarie  PF   26  WSB  101  219   860    500000   \n",
      "10639        2017        Cody Zeller  PF   24  CHO   65  189   639  12584270   \n",
      "10640        2017       Tyler Zeller   C   27  BOS   20   61   178   1709538   \n",
      "10641        2017  Stephen Zimmerman   C   20  ORL    3   17    23   1312611   \n",
      "10642        2017        Paul Zipser  SF   22  CHI   40   78   240   1312611   \n",
      "10643        2017        Ivica Zubac   C   19  LAL   30   66   284   1312611   \n",
      "\n",
      "       Salary Tier  \n",
      "0                1  \n",
      "1                1  \n",
      "2                2  \n",
      "3                1  \n",
      "4                1  \n",
      "10639            3  \n",
      "10640            0  \n",
      "10641            0  \n",
      "10642            0  \n",
      "10643            0  \n"
     ]
    }
   ],
   "source": [
    "add_salary_tiers(num_tiers, merged_data)\n",
    "if debug: \n",
    "    print(\"Merged With Salary Tier:\")\n",
    "    print(merged_data.iloc[list(range(5)) + list(range(-5, 0)), \n",
    "                   list(range(5)) + list(range(-5, 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_salary_info(merged_sal_tier: pd.DataFrame):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(15, 5)\n",
    "    merged_data['Salary Tier'].plot.hist(ax=ax1, bins=num_tiers, xticks=list(range(num_tiers)))\n",
    "    ax1.set_xlabel(\"Salary Tiers\")\n",
    "    merged_data.groupby('Season End')['Salary'].mean().sort_index().plot.bar(ax=ax2)\n",
    "    ax2.set_xlabel(\"Year\")\n",
    "    ax2.set_ylabel(\"Mean Salary\")\n",
    "    plt.show()\n",
    "\n",
    "if debug: plot_salary_info(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80/20 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged w_sal columns:\n",
      " Index(['Season End', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'PER',\n",
      "       'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%',\n",
      "       'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM',\n",
      "       'VORP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%',\n",
      "       'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK',\n",
      "       'TOV', 'PF', 'PTS', 'Salary', 'Salary Tier'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if debug: print(\"Merged w_sal columns:\\n\", merged_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_final_df(merged_w_sal: pd.DataFrame, to_omit: List[str]):\n",
    "    # Check that to_omit contains valid features\n",
    "    if all(feature in merged_w_sal.columns for feature in to_omit):\n",
    "        return merged_w_sal[[feature for feature in merged_w_sal.columns if not feature in to_omit]]\n",
    "    else:\n",
    "        raise ValueError(\"to_omit must contain valid features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmerged_data_final = construct_final_df(merged_data_final, \\n                                       [\\n                                        'Pos',\\n                                        'Age', \\n                                        'G', \\n                                        #'GS', \\n                                        'MP',\\n                                        #'PER',\\n                                        #'TS%',\\n                                        #'3PAr', \\n                                        #'FTr', \\n                                        #'ORB%', \\n                                        #'DRB%',\\n                                        'TRB%',\\n                                        #'AST%',\\n                                        #'STL%',\\n                                        #'BLK%',\\n                                        'TOV%',\\n                                        #'USG%',\\n                                        #'OWS',\\n                                        #'DWS',\\n                                        'WS',\\n                                        'WS/48',\\n                                        'OBPM', \\n                                        'DBPM',\\n                                        #'BMP',\\n                                        #'VORP', \\n                                        #'FG', \\n                                        #'FGA',\\n                                        'FG%',\\n                                        #'3P', \\n                                        #'3PA', \\n                                        '3P%', \\n                                        #'2P', \\n                                        #'2PA', \\n                                        '2P%',\\n                                        #'eFG%',\\n                                        #'FT',\\n                                        #'FTA', \\n                                        'FT%',\\n                                        #'ORB', \\n                                        #'DRB',\\n                                        'TRB',\\n                                        #'AST',\\n                                        #'STL',\\n                                        #'BLK',\\n                                        'TOV',\\n                                        #'PTS',\\n                                        'PF'\\n                                       ])\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_final = construct_final_df(merged_data, ['Player', 'Tm', 'Salary'])\n",
    "# TODO: Call something to make merged_data_final put categorical stuff first (or last)!!!\n",
    "\"\"\"\n",
    "merged_data_final = construct_final_df(merged_data_final, \n",
    "                                       [\n",
    "                                        'Pos',\n",
    "                                        'Age', \n",
    "                                        'G', \n",
    "                                        #'GS', \n",
    "                                        'MP',\n",
    "                                        #'PER',\n",
    "                                        #'TS%',\n",
    "                                        #'3PAr', \n",
    "                                        #'FTr', \n",
    "                                        #'ORB%', \n",
    "                                        #'DRB%',\n",
    "                                        'TRB%',\n",
    "                                        #'AST%',\n",
    "                                        #'STL%',\n",
    "                                        #'BLK%',\n",
    "                                        'TOV%',\n",
    "                                        #'USG%',\n",
    "                                        #'OWS',\n",
    "                                        #'DWS',\n",
    "                                        'WS',\n",
    "                                        'WS/48',\n",
    "                                        'OBPM', \n",
    "                                        'DBPM',\n",
    "                                        #'BMP',\n",
    "                                        #'VORP', \n",
    "                                        #'FG', \n",
    "                                        #'FGA',\n",
    "                                        'FG%',\n",
    "                                        #'3P', \n",
    "                                        #'3PA', \n",
    "                                        '3P%', \n",
    "                                        #'2P', \n",
    "                                        #'2PA', \n",
    "                                        '2P%',\n",
    "                                        #'eFG%',\n",
    "                                        #'FT',\n",
    "                                        #'FTA', \n",
    "                                        'FT%',\n",
    "                                        #'ORB', \n",
    "                                        #'DRB',\n",
    "                                        'TRB',\n",
    "                                        #'AST',\n",
    "                                        #'STL',\n",
    "                                        #'BLK',\n",
    "                                        'TOV',\n",
    "                                        #'PTS',\n",
    "                                        'PF'\n",
    "                                       ])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8515, 48) | y_train shape: (8515,)\n",
      "X_test shape: (2129, 48) | y_test shape: (2129,)\n"
     ]
    }
   ],
   "source": [
    "y = merged_data_final.pop('Salary Tier')\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_data_final, y, test_size=0.2)\n",
    "if debug: \n",
    "    print(\"X_train shape: {} | y_train shape: {}\".format(X_train.shape, y_train.shape))\n",
    "    print(\"X_test shape: {} | y_test shape: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO SOME FEATURE SELECTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding of Pos and Multicollinearity\n",
    "We see that we don't need to worry about multicollinearity from these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PF       1796\n",
      "C        1758\n",
      "PG       1680\n",
      "SG       1642\n",
      "SF       1515\n",
      "PG-SG      21\n",
      "SG-SF      19\n",
      "SF-SG      18\n",
      "PF-C       16\n",
      "C-PF       14\n",
      "SG-PG      14\n",
      "SF-PF      11\n",
      "PF-SF       8\n",
      "SG-PF       2\n",
      "PG-SF       1\n",
      "Name: Pos, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if debug: \n",
    "    if 'Pos' in X_train.columns:\n",
    "        print(X_train['Pos'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, note that Transformers don't like 1D numpy arrays\n",
    "#ohe = OneHotEncoder(sparse=False)\n",
    "#print(ohe.fit_transform(X_train['Pos'].values.reshape(-1, 1)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Transformation Pipeline\n",
    "We will use a ColumnTransformer to fit transformations in parallel rather than run `cat_pipe.fit_transform(cat_Xtrain)` and `num_pipe.fit_transform(num_Xtrain)` ourselves sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerMixin: Need to implem fit and transform, we get fit_transform which invokes both\n",
    "# BaseEstimator: We get get_params and set_params\n",
    "class YearlyScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Performs a Scaler Transform on the input DataFrame by year (groupby split-apply-combine strategy).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    year_col : The name of the column containing years (to use for splitting)\n",
    "    scaler : Some kind of Transformer\n",
    "    return_df : Return a pd.Dataframe if True\n",
    "    \"\"\"\n",
    "    def __init__(self, year_col: str, scaler: Type[Union[BaseEstimator, TransformerMixin]], \n",
    "                 return_df: bool = False):\n",
    "        # TODO: FOR SOME REASON THESE CAN'T BE MANGLED...\n",
    "        self.scaler = scaler\n",
    "        self.year_col = year_col\n",
    "        self.return_df = return_df\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame, shape [n_samples, n_features]\n",
    "            The data to fit.\n",
    "        y : Ignored\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self: object\n",
    "            Fitted scaler\n",
    "        \"\"\"\n",
    "        # TODO: ...BUT THESE CAN...\n",
    "        # Omit the groupby column\n",
    "        self._columns = [col for col in X.columns.values if col != self.year_col]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> Union[pd.DataFrame, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame, shape [n_samples, n_features]\n",
    "            The data used to scale along the features axis.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X_tr : array-like, shape [n_samples, n_features]\n",
    "            Transformed array.\n",
    "        \"\"\"\n",
    "        # Apply the self._scaler transform on all the numerical columns grouped by the Year column\n",
    "        # Remove the scaled Year column (iloc[:, 1:] says all rows, ignore 0th column, which is Year)\n",
    "        # Will give us a multi-indexed DF with the years as the 0-level index\n",
    "        X_tr = X[[self.year_col]+self._columns].groupby(self.year_col).apply(\n",
    "            lambda x, scaler=self.scaler: pd.DataFrame(scaler.fit_transform(x)).iloc[:, 1:])\n",
    "        # Drop the year index\n",
    "        X_tr.index = X_tr.index.droplevel(0)\n",
    "        \n",
    "        return X_tr if self.return_df else X_tr.to_numpy()\n",
    "\n",
    "    def get_feature_names(self) -> np.ndarray:\n",
    "        return np.array(self._columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_transformer(X_train: pd.DataFrame, \n",
    "                          scaler: Type[Union[BaseEstimator, TransformerMixin]],\n",
    "                          year_col: str, n_jobs: int = None) -> ColumnTransformer:\n",
    "    \"\"\"\n",
    "    n_jobs: -1 means use all processors. None means use 1.\n",
    "    \"\"\"\n",
    "    # Get column types\n",
    "    kinds = np.array([dt.kind for dt in X_train.dtypes])\n",
    "    all_columns = X_train.columns.values\n",
    "    is_num = kinds != 'O'\n",
    "    num_cols = all_columns[is_num]\n",
    "    cat_cols = all_columns[~is_num]\n",
    "\n",
    "    # Define labeled categorical transformation steps\n",
    "    # Dense matrix for potential time/space complexity\n",
    "    # When encountering unknown labels (for test transform), ignore them\n",
    "    cat_ohe_step = ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore')) \n",
    "\n",
    "    # Put the categorical transformations in a Pipeline to be executed sequentially\n",
    "    cat_steps = [cat_ohe_step]\n",
    "    cat_pipe = skPipeline(steps=cat_steps)\n",
    "\n",
    "    # Define labeled numerical transformation steps\n",
    "    num_scale_step = ('scale', YearlyScaler(year_col, scaler()))\n",
    "\n",
    "    # Would do the following if creating a Pipeline to feed to ColumnTransformer\n",
    "    # Put the numerical transformations in a Pipeline also\n",
    "    num_steps = [num_scale_step]\n",
    "    num_pipe = skPipeline(steps=num_steps)\n",
    "\n",
    "    cat_col_transformers = ('cat', cat_pipe, cat_cols)\n",
    "    num_col_transformers = ('num', num_pipe, num_cols)\n",
    "\n",
    "    by_col_transformers = [cat_col_transformers, num_col_transformers]\n",
    "\n",
    "    # Create ColumnTransformer which will apply transformations in parallel where possible\n",
    "    col_transformer = ColumnTransformer(transformers=by_col_transformers, n_jobs=n_jobs)\n",
    "    # We pass the whole training DataFrame because the transformers know which Pipelines\n",
    "    # to apply to which columns (specified in the 'transformers' list)\n",
    "    \n",
    "    return col_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineRFE(imbPipeline):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the following a new notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different scalers and run this cell\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = -1 # All processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following could be done in a loop but would require writing out all the arguments and storing in a dict or something, not worth it for just 3 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed shape: (8515, 61)\n",
      "Estimator rfc\n",
      "[0.34820904 0.32119789 0.33998826 0.32941867 0.34351145]\n",
      "(0.02497787925002842, 'USG%')\n",
      "(0.024630767459949666, 'DWS')\n",
      "(0.024223200853482264, 'FT%')\n",
      "(0.02374551398017362, '2PA')\n",
      "(0.023480011607602335, '3P%')\n",
      "(0.02344880934218935, '3P')\n",
      "(0.023019042963374817, 'x0_PG')\n",
      "(0.023013410648000488, 'OWS')\n",
      "(0.022859395676167987, 'FG%')\n",
      "(0.022857190771703905, 'BPM')\n",
      "(0.022673122878731834, 'VORP')\n",
      "(0.022462238191571587, '2P')\n",
      "(0.02242739011008155, '2P%')\n",
      "(0.022360579403827102, 'DRB')\n",
      "(0.02218812931861647, 'FG')\n",
      "(0.022075167865515003, 'x0_C-PF')\n",
      "(0.021955025826181456, 'FT')\n",
      "(0.021912286365883847, '3PA')\n",
      "(0.021703742669585132, 'x0_SG')\n",
      "(0.021575602687345152, 'WS/48')\n",
      "(0.021359175535926284, 'OBPM')\n",
      "(0.02110107982964966, 'STL')\n",
      "(0.021076456642177503, 'FGA')\n",
      "(0.021063618055124415, 'DBPM')\n",
      "(0.02084000090103393, 'x0_SF-SG')\n",
      "(0.02060250298664952, 'ORB')\n",
      "(0.020537486577350394, 'x0_PF')\n",
      "(0.02046916530831, 'x0_SG-PF')\n",
      "(0.02033058633274977, 'x0_SG-PG')\n",
      "(0.020309148942328346, 'eFG%')\n",
      "(0.01991096978885758, 'FTA')\n",
      "(0.019880168448102618, 'x0_PG-SF')\n",
      "(0.0198136857978331, 'x0_SF-PF')\n",
      "(0.019665993486538254, 'TOV')\n",
      "(0.01924852638172466, 'PF')\n",
      "(0.018998804500289953, 'x0_PF-SF')\n",
      "(0.018667739693594268, 'x0_PF-C')\n",
      "(0.01838343705018994, 'WS')\n",
      "(0.018356773761655544, 'x0_PG-SG')\n",
      "(0.017954673347619857, 'x0_SF')\n",
      "(0.017813049297173856, 'AST')\n",
      "(0.017740177437192514, 'BLK')\n",
      "(0.017567324455352487, 'PTS')\n",
      "(0.01743449229577969, 'x0_C')\n",
      "(0.016764357496228264, 'x0_SG-SF')\n",
      "(0.016620918422095565, 'TRB')\n",
      "(0.008284037211903197, 'GS')\n",
      "(0.008113683660387868, 'Age')\n",
      "(0.00792399708900211, 'TS%')\n",
      "(0.00750775687347811, 'AST%')\n",
      "(0.006566003110767493, 'ORB%')\n",
      "(0.000510820726280469, 'DRB%')\n",
      "(0.00030768863857822825, 'BLK%')\n",
      "(0.00024194843643456966, 'FTr')\n",
      "(0.00023194406769124642, 'TRB%')\n",
      "(9.288319057073561e-05, 'MP')\n",
      "(4.8614910477641433e-05, 'G')\n",
      "(3.337859848831378e-05, 'TOV%')\n",
      "(1.7584242094575343e-05, 'PER')\n",
      "(1.1259613298402662e-05, '3PAr')\n",
      "(9.57898900708651e-06, 'STL%')\n",
      "Score on Test Set: 0.3400657585720996\n",
      "ROC_AUC: 0.5082543046825646\n",
      "Precision, recall, f_score, support:\n",
      "(array([0.44913338, 0.22748815, 0.12935323, 0.04411765, 0.05882353,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ]), array([0.61889927, 0.18860511, 0.11453744, 0.01986755, 0.025     ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ]), array([0.52052402, 0.20622986, 0.12149533, 0.02739726, 0.03508772,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ]), array([963, 509, 227, 151, 120,  79,  38,  24,  11,   7]))\n",
      "\n",
      "\n",
      "Estimator lgreg\n",
      "[0.06752789 0.08807986 0.07985907 0.07692308 0.08103347]\n",
      "Score on Test Set: 0.08548614372945045\n",
      "ROC_AUC: 0.5206933608192581\n",
      "Precision, recall, f_score, support:\n",
      "(array([0.4017094 , 0.17006803, 0.10457516, 0.07189542, 0.05050505,\n",
      "       0.04081633, 0.02816901, 0.01444043, 0.00325733, 0.        ]), array([0.09761163, 0.04911591, 0.07048458, 0.14569536, 0.08333333,\n",
      "       0.07594937, 0.10526316, 0.16666667, 0.09090909, 0.        ]), array([0.15705931, 0.07621951, 0.08421053, 0.09628009, 0.06289308,\n",
      "       0.05309735, 0.04444444, 0.02657807, 0.00628931, 0.        ]), array([963, 509, 227, 151, 120,  79,  38,  24,  11,   7]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scalers = [MinMaxScaler, StandardScaler]\n",
    "estimators = {\n",
    "              'rfc': [RandomForestClassifier(n_jobs=n_jobs)], \n",
    "              'lgreg': [LogisticRegression(max_iter=4000, n_jobs=n_jobs)], \n",
    "              #'mlp': [MLPClassifier(activation='logistic', max_iter=200),\n",
    "              #       MLPClassifier(activation='tanh', max_iter=200)]\n",
    "             }\n",
    "\n",
    "def runEstimatorPipelineAndDisplayMetrics(X_train, y_train, X_test, y_test,\n",
    "                                          scalers: List[Union[BaseEstimator, TransformerMixin]],\n",
    "                                          estimators,\n",
    "                                          over_sampling=False):\n",
    "    \"\"\"\n",
    "    Blah\n",
    "    \"\"\"\n",
    "    for scaler in scalers:\n",
    "        col_transformer = construct_transformer(X_train, scaler, 'Season End', n_jobs)\n",
    "        if debug:\n",
    "            X_train_transformed = col_transformer.fit_transform(X_train)\n",
    "            print(\"Transformed shape:\", X_train_transformed.shape)\n",
    "        for key, vals in estimators.items():\n",
    "            idx = 1 if scaler == StandardScaler and key == 'mlp' else 0\n",
    "            print(\"Estimator\", key)\n",
    "            if over_sampling:\n",
    "                # SMOTE step will be skipped when scoring and predicting\n",
    "                ml_pipe = imbPipeline(steps=[('transform', col_transformer), \n",
    "                                  ('smote', SMOTE('not majority')),\n",
    "                                  ('est', vals[idx])])\n",
    "            else:\n",
    "                ml_pipe = skPipeline(steps[('transform', col_transformer), \n",
    "                                  ('est', vals[idx])])\n",
    "            ml_pipe.fit(X_train, y_train)\n",
    "            \n",
    "            scores = cross_val_score(ml_pipe, X_train, y_train, cv=5)\n",
    "            print(\"5-Fold CV Scores:\")\n",
    "            print(scores)\n",
    "            \n",
    "            transform_steps = ml_pipe.named_steps['transform']\n",
    "            feats = list(transform_steps.named_transformers_['num'].named_steps['scale'].get_feature_names())\n",
    "            if 'cat' in transform_steps.named_transformers_:\n",
    "                feats += list(transform_steps.named_transformers_['cat'].named_steps['ohe'].get_feature_names())\n",
    "            if key == 'rfc':\n",
    "                importances = ml_pipe.named_steps['est'].feature_importances_\n",
    "                print(\"Sorted Features and Importances:\")\n",
    "                for feature in sorted(zip(importances, feats), reverse=True):\n",
    "                    print(feature)\n",
    "                \n",
    "            print(\"Score on Test Set:\", ml_pipe.score(X_test, y_test))\n",
    "            print(\"ROC_AUC:\", roc_auc_score(y_test, ml_pipe.predict_proba(X_test), \n",
    "                                            average='weighted', multi_class='ovo'))\n",
    "            print(\"Precision, recall, f_score, support:\")\n",
    "            print(precision_recall_fscore_support(y_test, ml_pipe.predict(X_test)))\n",
    "            print('\\n')\n",
    "\n",
    "runEstimatorPipelineAndDisplayMetrics(X_train, y_train, X_test, y_test, scalers, estimators, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
