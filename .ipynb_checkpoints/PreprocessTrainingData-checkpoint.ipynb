{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Type, Union\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.getcwd()\n",
    "data_dir = os.path.join(src_dir, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_file = os.path.join(data_dir, \"nba_stats_sal_merged_1990_2017.csv\")\n",
    "merged_data = pd.read_csv(merged_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Season End             Player Pos  Age   Tm  BLK  TOV   PF   PTS  \\\n",
      "0            1990         Mark Acres   C   27  ORL   25   70  248   362   \n",
      "1            1990      Michael Adams  PG   27  DEN    3  141  133  1221   \n",
      "2            1990       Mark Aguirre  SF   30  DET   19  121  201  1099   \n",
      "3            1990        Danny Ainge  PG   30  SAC   18  185  238  1342   \n",
      "4            1990        Mark Alarie  PF   26  WSB   39  101  219   860   \n",
      "10639        2017        Cody Zeller  PF   24  CHO   58   65  189   639   \n",
      "10640        2017       Tyler Zeller   C   27  BOS   21   20   61   178   \n",
      "10641        2017  Stephen Zimmerman   C   20  ORL    5    3   17    23   \n",
      "10642        2017        Paul Zipser  SF   22  CHI   16   40   78   240   \n",
      "10643        2017        Ivica Zubac   C   19  LAL   33   30   66   284   \n",
      "\n",
      "         Salary  \n",
      "0        437000  \n",
      "1        825000  \n",
      "2       1115000  \n",
      "3        725000  \n",
      "4        500000  \n",
      "10639  12584270  \n",
      "10640   1709538  \n",
      "10641   1312611  \n",
      "10642   1312611  \n",
      "10643   1312611  \n"
     ]
    }
   ],
   "source": [
    "print(merged_data.iloc[list(range(5)) + list(range(-5, 0)), \n",
    "                   list(range(5)) + list(range(-5, 0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps\n",
    "- Already took care of null data (when reading from original CSVs and merging)\n",
    "- Try different normalization, standardization techniques and see effect on performance\n",
    "- The only categorical variable to be encoded is Position; not using Team unfortunately b/c a) teams have changed and b) some players played for multiple teams, and thus have TOT as their team. Note that this variable is not ordinal, it's nominal. Also, beware multicollinearity.\n",
    "- Split data by year, do scaling on separate DataFrames, then concatenate.\n",
    "- Write different scaled data to different CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Salary Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tiers = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Max Salaries Per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of rows grouped by Season End\n",
    "salary_maxes = merged_data.groupby('Season End')['Salary'].max().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Player Salary Tier in New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_tiers = []\n",
    "for index, row in merged_data[['Season End', 'Salary']].iterrows():\n",
    "    # +1 so we have num_tiers tiers (so the max falls in the highest tier)\n",
    "    player_tiers.append(int(row['Salary'] / (salary_maxes[row['Season End']]+1) * num_tiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'Salary Tier' in merged_data.columns: \n",
    "    merged_data.insert(len(merged_data.columns), 'Salary Tier', pd.Series(player_tiers))\n",
    "else:\n",
    "    merged_data['Salary Tier'] = pd.Series(player_tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Season End             Player Pos  Age   Tm  TOV   PF   PTS    Salary  \\\n",
      "0            1990         Mark Acres   C   27  ORL   70  248   362    437000   \n",
      "1            1990      Michael Adams  PG   27  DEN  141  133  1221    825000   \n",
      "2            1990       Mark Aguirre  SF   30  DET  121  201  1099   1115000   \n",
      "3            1990        Danny Ainge  PG   30  SAC  185  238  1342    725000   \n",
      "4            1990        Mark Alarie  PF   26  WSB  101  219   860    500000   \n",
      "10639        2017        Cody Zeller  PF   24  CHO   65  189   639  12584270   \n",
      "10640        2017       Tyler Zeller   C   27  BOS   20   61   178   1709538   \n",
      "10641        2017  Stephen Zimmerman   C   20  ORL    3   17    23   1312611   \n",
      "10642        2017        Paul Zipser  SF   22  CHI   40   78   240   1312611   \n",
      "10643        2017        Ivica Zubac   C   19  LAL   30   66   284   1312611   \n",
      "\n",
      "       Salary Tier  \n",
      "0                0  \n",
      "1                0  \n",
      "2                1  \n",
      "3                0  \n",
      "4                0  \n",
      "10639            1  \n",
      "10640            0  \n",
      "10641            0  \n",
      "10642            0  \n",
      "10643            0  \n"
     ]
    }
   ],
   "source": [
    "print(merged_data.iloc[list(range(5)) + list(range(-5, 0)), \n",
    "                   list(range(5)) + list(range(-5, 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15, 5)\n",
    "merged_data['Salary Tier'].plot.hist(ax=ax1, bins=num_tiers, xticks=[0, 1, 2, 3, 4])\n",
    "ax1.set_xlabel(\"Salary Tiers\")\n",
    "merged_data.groupby('Season End')['Salary'].mean().sort_index().plot.bar(ax=ax2)\n",
    "ax2.set_xlabel(\"Year\")\n",
    "ax2.set_ylabel(\"Mean Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80/20 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Season End', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'PER',\n",
       "       'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%',\n",
       "       'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM',\n",
       "       'VORP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%',\n",
       "       'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK',\n",
       "       'TOV', 'PF', 'PTS', 'Salary', 'Salary Tier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8515, 48) (8515,)\n",
      "(2129, 48) (2129,)\n",
      "      Season End Pos  Age   G  GS    MP   PER    TS%   3PAr    FTr  ...  \\\n",
      "5346        2005  PG   26  80  80  3084  19.2  0.543  0.288  0.327  ...   \n",
      "4384        2002  PF   26  59   5   650  12.7  0.492  0.014  0.370  ...   \n",
      "7405        2010  SF   23  67  38  1730  11.5  0.512  0.094  0.274  ...   \n",
      "6696        2008   C   32  73  73  2222  18.7  0.522  0.001  0.276  ...   \n",
      "9777        2015  PG   26  67  67  2302  29.1  0.536  0.196  0.445  ...   \n",
      "\n",
      "        FT%  ORB  DRB  TRB  AST  STL  BLK  TOV   PF   PTS  \n",
      "5346  0.775   77  255  332  541  124   30  203  191  1571  \n",
      "4384  0.648   89   73  162   44   16   13   22  104   167  \n",
      "7405  0.847   45  153  198   93   55   19   97  101   657  \n",
      "6696  0.802  263  419  682  104   34  120  135  247  1029  \n",
      "9777  0.835  124  364  488  574  140   14  293  184  1886  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data_final = merged_data.drop('Player', axis=1).drop('Tm', axis=1).drop('Salary', axis=1)\n",
    "y = merged_data_final.pop('Salary Tier')\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_data_final, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of Position\n",
    "We see that we don't need to worry about multicollinearity from these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PF       1807\n",
      "C        1778\n",
      "PG       1657\n",
      "SG       1607\n",
      "SF       1541\n",
      "SG-SF      24\n",
      "PG-SG      19\n",
      "SF-SG      18\n",
      "PF-C       15\n",
      "C-PF       13\n",
      "SF-PF      12\n",
      "SG-PG      12\n",
      "PF-SF       9\n",
      "SG-PF       3\n",
      "Name: Pos, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train['Pos'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8515, 14)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(X_train['Pos'].values.reshape(-1, 1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Transformation Pipeline\n",
    "We will use a ColumnTransformer to fit transformations in parallel rather than run `cat_pipe.fit_transform(cat_Xtrain)` and `num_pipe.fit_transform(num_Xtrain)` ourselves sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerMixin: Need to implem fit and transform, we get fit_transform which invokes both\n",
    "# BaseEstimator: We get get_params and set_params\n",
    "class YearlyScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, year_col: str, scaler: Type[Union[BaseEstimator, TransformerMixin]], \n",
    "                 return_df: bool = False):\n",
    "        # FOR SOME FUCKING REASON THESE CAN'T BE MANGLED ARRRRGGHGHHGHGHGHGHGH\n",
    "        self.scaler = scaler\n",
    "        self.year_col = year_col\n",
    "        self.return_df = return_df\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        \"\"\"Blah\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame, shape [n_samples, n_features]\n",
    "            The data used to blah.\n",
    "        y : Ignored\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self: object\n",
    "            Fitted scaler\n",
    "        \"\"\"\n",
    "        # Omit the groupby column\n",
    "        #print(self._year_col)\n",
    "        self._columns = [col for col in X.columns.values if col != self.year_col]\n",
    "        print(self._columns)\n",
    "        \n",
    "        # Split data into categorical and numeric;\n",
    "        # we only want to scale the numerical data\n",
    "        #self._dtypes = X.dtypes.values\n",
    "        #self._kinds = np.array([dt.kind for dt in X.dtypes])\n",
    "        #self._column_dtypes = {}\n",
    "        #is_categorical = self._kinds == 'O'  # Mask over _kinds\n",
    "        #self._column_dtypes['cat'] = self._columns[is_categorical]\n",
    "        #self._column_dtypes['num'] = self._columns[~is_categorical]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> Union[pd.DataFrame, np.ndarray]:\n",
    "        \"\"\"Blah\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame, shape [n_samples, n_features]\n",
    "            The data used to scale along the features axis.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X_tr : array-like, shape [n_samples, n_features]\n",
    "            Transformed array.\n",
    "        \"\"\"\n",
    "        # Apply the self._scaler transform on all the numerical columns grouped by the Year column\n",
    "        # Remove the scaled Year column (iloc[:, 1:] says all rows, ignore 0th column, which is Year)\n",
    "        # Will give us a multi-indexed DF with the years as the 0-level index\n",
    "        #print(X[[self._year_col] + self._columns])\n",
    "        X_tr = X[[self.year_col]+self._columns].groupby(self.year_col).apply(\n",
    "            lambda x, scaler=self.scaler: pd.DataFrame(scaler.fit_transform(x)).iloc[:, 1:])\n",
    "        # Drop the year index\n",
    "        X_tr.index = X_tr.index.droplevel(0)\n",
    "        \n",
    "        return X_tr if self.return_df else X_tr.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "def f(df: pd.DataFrame, scaler: Type[Union[BaseEstimator, TransformerMixin]]) -> pd.DataFrame:\n",
    "    return pd.DataFrame(scaler.fit_transform(df)).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season End</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1990</th>\n",
       "      <th>0</th>\n",
       "      <td>0.070492</td>\n",
       "      <td>1.560433</td>\n",
       "      <td>2.026737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.110583</td>\n",
       "      <td>-0.443148</td>\n",
       "      <td>-0.654850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.110583</td>\n",
       "      <td>-1.318402</td>\n",
       "      <td>-1.087187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956299</td>\n",
       "      <td>1.430029</td>\n",
       "      <td>2.570351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.137374</td>\n",
       "      <td>-1.423389</td>\n",
       "      <td>-1.198464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017</th>\n",
       "      <th>361</th>\n",
       "      <td>2.291372</td>\n",
       "      <td>0.585530</td>\n",
       "      <td>-0.087307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.440065</td>\n",
       "      <td>-0.794313</td>\n",
       "      <td>-0.754116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>-0.022762</td>\n",
       "      <td>1.790074</td>\n",
       "      <td>2.653553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>-1.411242</td>\n",
       "      <td>-0.873197</td>\n",
       "      <td>-0.587939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.208651</td>\n",
       "      <td>-1.211271</td>\n",
       "      <td>-0.985501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1         2         3\n",
       "Season End                                  \n",
       "1990       0    0.070492  1.560433  2.026737\n",
       "           1   -1.110583 -0.443148 -0.654850\n",
       "           2   -1.110583 -1.318402 -1.087187\n",
       "           3    0.956299  1.430029  2.570351\n",
       "           4    2.137374 -1.423389 -1.198464\n",
       "...                  ...       ...       ...\n",
       "2017       361  2.291372  0.585530 -0.087307\n",
       "           362  0.440065 -0.794313 -0.754116\n",
       "           363 -0.022762  1.790074  2.653553\n",
       "           364 -1.411242 -0.873197 -0.587939\n",
       "           365  0.208651 -1.211271 -0.985501\n",
       "\n",
       "[8515 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = X_train[['Season End']+['Age', 'MP', 'PTS']].groupby('Season End').apply(\n",
    "    lambda x, scaler=std_scaler: pd.DataFrame(scaler.fit_transform(x)).iloc[:, 1:])\n",
    "#a.index = a.index.droplevel(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8515, 3)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = minmax_scaler.fit_transform(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06778312,  0.13795273, -0.19228128],\n",
       "       [-0.47487527, -1.54908328, -1.11677818],\n",
       "       [ 0.11803258, -0.95416968, -0.92938016],\n",
       "       ...,\n",
       "       [-0.07021224, -0.23593321, -0.36655774],\n",
       "       [-0.07021224,  1.6781692 ,  2.42502248],\n",
       "       [-1.2415415 ,  2.11697046,  2.74394487]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler.fit_transform(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
      "(8515, 60)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.779346</td>\n",
       "      <td>1.297094</td>\n",
       "      <td>1.560433</td>\n",
       "      <td>0.653194</td>\n",
       "      <td>-0.112714</td>\n",
       "      <td>-0.420631</td>\n",
       "      <td>0.165709</td>\n",
       "      <td>0.317561</td>\n",
       "      <td>-0.709747</td>\n",
       "      <td>-0.385605</td>\n",
       "      <td>-0.177595</td>\n",
       "      <td>0.096807</td>\n",
       "      <td>-0.479121</td>\n",
       "      <td>-0.529946</td>\n",
       "      <td>2.038931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110583</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>-0.492979</td>\n",
       "      <td>-0.443148</td>\n",
       "      <td>-1.156995</td>\n",
       "      <td>-1.110949</td>\n",
       "      <td>-0.400826</td>\n",
       "      <td>-0.181342</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>-1.230504</td>\n",
       "      <td>-0.804322</td>\n",
       "      <td>-0.964303</td>\n",
       "      <td>-0.240751</td>\n",
       "      <td>-0.408774</td>\n",
       "      <td>-1.268015</td>\n",
       "      <td>-0.702185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110583</td>\n",
       "      <td>-1.280354</td>\n",
       "      <td>-1.017656</td>\n",
       "      <td>-1.318402</td>\n",
       "      <td>-1.243194</td>\n",
       "      <td>-1.610066</td>\n",
       "      <td>0.203223</td>\n",
       "      <td>-1.605699</td>\n",
       "      <td>-1.484131</td>\n",
       "      <td>-0.848615</td>\n",
       "      <td>-1.199777</td>\n",
       "      <td>0.629284</td>\n",
       "      <td>-0.690829</td>\n",
       "      <td>-0.760510</td>\n",
       "      <td>-0.406935</td>\n",
       "      <td>-0.111791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.956299</td>\n",
       "      <td>0.726533</td>\n",
       "      <td>1.297094</td>\n",
       "      <td>1.430029</td>\n",
       "      <td>1.472089</td>\n",
       "      <td>0.868884</td>\n",
       "      <td>-0.232484</td>\n",
       "      <td>0.454919</td>\n",
       "      <td>-0.496107</td>\n",
       "      <td>0.227616</td>\n",
       "      <td>0.033112</td>\n",
       "      <td>-0.419659</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>-0.268080</td>\n",
       "      <td>-0.972787</td>\n",
       "      <td>1.996760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137374</td>\n",
       "      <td>-0.540975</td>\n",
       "      <td>-1.202836</td>\n",
       "      <td>-1.423389</td>\n",
       "      <td>-0.467399</td>\n",
       "      <td>0.952070</td>\n",
       "      <td>2.698638</td>\n",
       "      <td>-1.439404</td>\n",
       "      <td>-1.077297</td>\n",
       "      <td>-1.039560</td>\n",
       "      <td>-1.129990</td>\n",
       "      <td>0.790660</td>\n",
       "      <td>-0.015712</td>\n",
       "      <td>-0.690163</td>\n",
       "      <td>0.724770</td>\n",
       "      <td>-1.355836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.291372</td>\n",
       "      <td>0.756499</td>\n",
       "      <td>-0.305410</td>\n",
       "      <td>0.585530</td>\n",
       "      <td>-0.579425</td>\n",
       "      <td>-0.297801</td>\n",
       "      <td>1.140561</td>\n",
       "      <td>-0.470701</td>\n",
       "      <td>-0.054995</td>\n",
       "      <td>0.828068</td>\n",
       "      <td>0.555710</td>\n",
       "      <td>0.248446</td>\n",
       "      <td>-0.302313</td>\n",
       "      <td>-0.220911</td>\n",
       "      <td>0.947875</td>\n",
       "      <td>-0.556237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440065</td>\n",
       "      <td>-1.002019</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>-0.794313</td>\n",
       "      <td>-1.089344</td>\n",
       "      <td>-1.357457</td>\n",
       "      <td>0.473731</td>\n",
       "      <td>-0.438128</td>\n",
       "      <td>-0.943000</td>\n",
       "      <td>-0.217297</td>\n",
       "      <td>-0.604641</td>\n",
       "      <td>-0.052437</td>\n",
       "      <td>-0.064107</td>\n",
       "      <td>-0.610253</td>\n",
       "      <td>-0.710009</td>\n",
       "      <td>-0.148293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022762</td>\n",
       "      <td>0.976314</td>\n",
       "      <td>1.871659</td>\n",
       "      <td>1.790074</td>\n",
       "      <td>1.498022</td>\n",
       "      <td>0.449392</td>\n",
       "      <td>0.454262</td>\n",
       "      <td>-0.144965</td>\n",
       "      <td>-0.745666</td>\n",
       "      <td>-0.715090</td>\n",
       "      <td>-0.801682</td>\n",
       "      <td>1.699133</td>\n",
       "      <td>0.054996</td>\n",
       "      <td>-0.610253</td>\n",
       "      <td>-0.629136</td>\n",
       "      <td>1.965600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.411242</td>\n",
       "      <td>-1.045982</td>\n",
       "      <td>-0.519548</td>\n",
       "      <td>-0.873197</td>\n",
       "      <td>0.648157</td>\n",
       "      <td>0.558075</td>\n",
       "      <td>-1.385605</td>\n",
       "      <td>0.349069</td>\n",
       "      <td>1.203013</td>\n",
       "      <td>0.960813</td>\n",
       "      <td>1.190619</td>\n",
       "      <td>-0.621966</td>\n",
       "      <td>-0.302313</td>\n",
       "      <td>0.168431</td>\n",
       "      <td>0.058279</td>\n",
       "      <td>0.500709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208651</td>\n",
       "      <td>-0.826167</td>\n",
       "      <td>-0.947823</td>\n",
       "      <td>-1.211271</td>\n",
       "      <td>-1.410404</td>\n",
       "      <td>-1.479725</td>\n",
       "      <td>-0.382927</td>\n",
       "      <td>-0.807296</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>-0.051366</td>\n",
       "      <td>-0.013519</td>\n",
       "      <td>-0.987324</td>\n",
       "      <td>0.888716</td>\n",
       "      <td>-0.091130</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>-0.296636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8515 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10   11   12   13        14        15        16        17        18  \\\n",
       "0     0.0  0.0  0.0  0.0  0.070492  0.779346  1.297094  1.560433  0.653194   \n",
       "1     0.0  0.0  0.0  0.0 -1.110583  0.092779 -0.492979 -0.443148 -1.156995   \n",
       "2     0.0  0.0  0.0  0.0 -1.110583 -1.280354 -1.017656 -1.318402 -1.243194   \n",
       "3     0.0  0.0  0.0  0.0  0.956299  0.726533  1.297094  1.430029  1.472089   \n",
       "4     0.0  0.0  0.0  0.0  2.137374 -0.540975 -1.202836 -1.423389 -0.467399   \n",
       "...   ...  ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "8510  0.0  0.0  0.0  0.0  2.291372  0.756499 -0.305410  0.585530 -0.579425   \n",
       "8511  0.0  0.0  0.0  0.0  0.440065 -1.002019  0.265625 -0.794313 -1.089344   \n",
       "8512  0.0  0.0  0.0  0.0 -0.022762  0.976314  1.871659  1.790074  1.498022   \n",
       "8513  0.0  0.0  0.0  0.0 -1.411242 -1.045982 -0.519548 -0.873197  0.648157   \n",
       "8514  0.0  0.0  0.0  0.0  0.208651 -0.826167 -0.947823 -1.211271 -1.410404   \n",
       "\n",
       "            19        20        21        22        23        24        25  \\\n",
       "0    -0.112714 -0.420631  0.165709  0.317561 -0.709747 -0.385605 -0.177595   \n",
       "1    -1.110949 -0.400826 -0.181342  0.085084 -1.230504 -0.804322 -0.964303   \n",
       "2    -1.610066  0.203223 -1.605699 -1.484131 -0.848615 -1.199777  0.629284   \n",
       "3     0.868884 -0.232484  0.454919 -0.496107  0.227616  0.033112 -0.419659   \n",
       "4     0.952070  2.698638 -1.439404 -1.077297 -1.039560 -1.129990  0.790660   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8510 -0.297801  1.140561 -0.470701 -0.054995  0.828068  0.555710  0.248446   \n",
       "8511 -1.357457  0.473731 -0.438128 -0.943000 -0.217297 -0.604641 -0.052437   \n",
       "8512  0.449392  0.454262 -0.144965 -0.745666 -0.715090 -0.801682  1.699133   \n",
       "8513  0.558075 -1.385605  0.349069  1.203013  0.960813  1.190619 -0.621966   \n",
       "8514 -1.479725 -0.382927 -0.807296  0.019006 -0.051366 -0.013519 -0.987324   \n",
       "\n",
       "            26        27        28        29  \n",
       "0     0.096807 -0.479121 -0.529946  2.038931  \n",
       "1    -0.240751 -0.408774 -1.268015 -0.702185  \n",
       "2    -0.690829 -0.760510 -0.406935 -0.111791  \n",
       "3    -0.353271 -0.268080 -0.972787  1.996760  \n",
       "4    -0.015712 -0.690163  0.724770 -1.355836  \n",
       "...        ...       ...       ...       ...  \n",
       "8510 -0.302313 -0.220911  0.947875 -0.556237  \n",
       "8511 -0.064107 -0.610253 -0.710009 -0.148293  \n",
       "8512  0.054996 -0.610253 -0.629136  1.965600  \n",
       "8513 -0.302313  0.168431  0.058279  0.500709  \n",
       "8514  0.888716 -0.091130  0.017843 -0.296636  \n",
       "\n",
       "[8515 rows x 20 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column types\n",
    "kinds = np.array([dt.kind for dt in X_train.dtypes])\n",
    "all_columns = X_train.columns.values\n",
    "is_num = kinds != 'O'\n",
    "num_cols = all_columns[is_num]\n",
    "cat_cols = all_columns[~is_num]\n",
    "\n",
    "# Define labeled categorical transformation steps\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore')) # Dense matrix for potential time/space complexity\n",
    "\n",
    "# Put the categorical transformations in a Pipeline to be executed sequentially\n",
    "cat_steps = [cat_ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "\n",
    "# Define labeled numerical transformation steps\n",
    "num_scale_step = ('scale', YearlyScaler('Season End', StandardScaler(), return_df=True))\n",
    "\n",
    "# Would do the following if creating a Pipeline to feed to ColumnTransformer\n",
    "# Put the numerical transformations in a Pipeline also\n",
    "num_steps = [num_scale_step]\n",
    "num_pipe = Pipeline(num_steps)\n",
    "\n",
    "cat_col_transformers = ('cat', cat_pipe, cat_cols)\n",
    "num_col_transformers = ('num', num_pipe, num_cols)\n",
    "\n",
    "by_col_transformers = [cat_col_transformers, num_col_transformers]\n",
    "\n",
    "# Create ColumnTransformer which will apply transformations in parallel where possible\n",
    "col_transformer = ColumnTransformer(transformers=by_col_transformers)\n",
    "# We pass the whole training DataFrame because the transformers know which Pipelines\n",
    "# to apply to which columns (specified in the 'transformers' list)\n",
    "X_train_transformed = col_transformer.fit_transform(X_train)\n",
    "\n",
    "#transform_pipe = Pipeline([num_scale_step, ('ct', col_transformer)])\n",
    "#X_train_transformed = transform_pipe.fit_transform(X_train)\n",
    "\n",
    "print(X_train_transformed.shape)\n",
    "pd.DataFrame(X_train_transformed).iloc[:, 10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transform',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop=None,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 sparse=False))],\n",
       "                                                           verbose=False),\n",
       "                                                  array(['Pos'], dtype=object)),\n",
       "                                                 ('num...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "ml_pipe = Pipeline([('transform', col_transformer), ('rfc', RandomForestClassifier())])\n",
    "ml_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956547269524368"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6712071395021136"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
